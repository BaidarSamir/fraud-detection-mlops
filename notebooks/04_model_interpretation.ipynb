{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f677227f",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection - Model Interpretation\n",
    "\n",
    "## Overview\n",
    "This notebook provides comprehensive model interpretation for the fraud detection system.\n",
    "Explainability is critical in fraud detection for:\n",
    "1. **Regulatory Compliance**: Many jurisdictions require explainable AI decisions\n",
    "2. **Fraud Analyst Trust**: Analysts need to understand why transactions are flagged\n",
    "3. **Model Debugging**: Identify if model is learning spurious correlations\n",
    "4. **Continuous Improvement**: Understand failure modes to improve the model\n",
    "\n",
    "## Interpretation Methods\n",
    "1. **Feature Importance**: Which features contribute most to predictions\n",
    "2. **SHAP Values**: Local explanations for individual predictions\n",
    "3. **Error Analysis**: Understanding false positives and false negatives\n",
    "4. **Partial Dependence**: How features affect predictions globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = Path('..').resolve()\n",
    "PROCESSED_PATH = BASE_PATH / 'Data' / 'processed'\n",
    "FEATURES_PATH = BASE_PATH / 'Data' / 'features'\n",
    "OUTPUT_PATH = BASE_PATH / 'outputs'\n",
    "MODELS_PATH = OUTPUT_PATH / 'models'\n",
    "VISUALS_PATH = OUTPUT_PATH / 'visuals'\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(BASE_PATH / 'src'))\n",
    "\n",
    "print(f\"Base Path: {BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65994c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and artifacts\n",
    "print(\"Loading model and data...\")\n",
    "\n",
    "with open(MODELS_PATH / 'best_model.pkl', 'rb') as f:\n",
    "    model_artifacts = pickle.load(f)\n",
    "\n",
    "model = model_artifacts['model']\n",
    "model_name = model_artifacts['model_name']\n",
    "optimal_threshold = model_artifacts['optimal_threshold']\n",
    "feature_cols = model_artifacts['feature_cols']\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Number of Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9eb191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "train_df = pd.read_parquet(PROCESSED_PATH / 'train_processed.parquet')\n",
    "\n",
    "# Time-based split (same as in modeling)\n",
    "train_df_sorted = train_df.sort_values('TransactionDT').reset_index(drop=True)\n",
    "split_idx = int(len(train_df_sorted) * 0.8)\n",
    "val_data = train_df_sorted.iloc[split_idx:]\n",
    "\n",
    "# Prepare features\n",
    "available_features = [c for c in feature_cols if c in val_data.columns]\n",
    "X_val = val_data[available_features]\n",
    "y_val = val_data['isFraud']\n",
    "\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Fraud rate: {y_val.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(f\"Predictions generated for {len(y_pred)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da5ca3",
   "metadata": {},
   "source": [
    "## 1. Feature Importance Analysis\n",
    "\n",
    "Feature importance helps understand which features the model relies on most.\n",
    "For tree-based models, we can use:\n",
    "- **Gain**: Average improvement in split criterion when feature is used\n",
    "- **Split**: Number of times feature is used for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "else:\n",
    "    # For models without direct feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': [1/len(available_features)] * len(available_features)\n",
    "    })\n",
    "\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(importance_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Top 15 Feature Importance\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "top_15 = importance_df.head(15)\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, 15))[::-1]\n",
    "\n",
    "bars = ax.barh(range(len(top_15)), top_15['importance'].values, color=colors, edgecolor='black')\n",
    "ax.set_yticks(range(len(top_15)))\n",
    "ax.set_yticklabels(top_15['feature'].values)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "ax.set_title('Top 15 Most Important Features for Fraud Detection', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add importance values as text\n",
    "for bar, imp in zip(bars, top_15['importance'].values):\n",
    "    ax.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "            f'{imp:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(VISUALS_PATH / 'feature_importance_top15.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {VISUALS_PATH / 'feature_importance_top15.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance by category\n",
    "def categorize_feature(feature_name):\n",
    "    \"\"\"Categorize features by their prefix/type.\"\"\"\n",
    "    if feature_name.startswith('V'):\n",
    "        return 'Vesta Features'\n",
    "    elif feature_name.startswith('C'):\n",
    "        return 'Counting Features'\n",
    "    elif feature_name.startswith('D'):\n",
    "        return 'Timedelta Features'\n",
    "    elif feature_name.startswith('M'):\n",
    "        return 'Match Features'\n",
    "    elif feature_name.startswith('id_'):\n",
    "        return 'Identity Features'\n",
    "    elif feature_name.startswith('card'):\n",
    "        return 'Card Features'\n",
    "    elif feature_name.startswith('addr'):\n",
    "        return 'Address Features'\n",
    "    elif 'email' in feature_name.lower():\n",
    "        return 'Email Features'\n",
    "    elif feature_name in ['hour', 'day', 'day_of_week', 'hour_sin', 'hour_cos', \n",
    "                          'dow_sin', 'dow_cos', 'is_night', 'is_weekend', 'is_business_hours']:\n",
    "        return 'Temporal Features'\n",
    "    elif 'TransactionAmt' in feature_name:\n",
    "        return 'Amount Features'\n",
    "    else:\n",
    "        return 'Other Features'\n",
    "\n",
    "importance_df['category'] = importance_df['feature'].apply(categorize_feature)\n",
    "\n",
    "# Aggregate importance by category\n",
    "category_importance = importance_df.groupby('category')['importance'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance by Category:\")\n",
    "print(category_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4084176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Importance by Category\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(category_importance)))\n",
    "bars = ax.bar(range(len(category_importance)), category_importance.values, color=colors, edgecolor='black')\n",
    "ax.set_xticks(range(len(category_importance)))\n",
    "ax.set_xticklabels(category_importance.index, rotation=45, ha='right')\n",
    "ax.set_ylabel('Total Importance', fontsize=12)\n",
    "ax.set_title('Feature Importance by Category', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add values on bars\n",
    "for bar, val in zip(bars, category_importance.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f'{val:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(VISUALS_PATH / 'feature_importance_by_category.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e46141",
   "metadata": {},
   "source": [
    "## 2. SHAP Value Analysis\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) provides:\n",
    "- **Global interpretability**: Which features matter most overall\n",
    "- **Local interpretability**: Why a specific prediction was made\n",
    "- **Feature interaction**: How features work together\n",
    "\n",
    "Note: SHAP computation can be slow for large datasets, so we sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9962e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to import SHAP, install if not available\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "    print(\"SHAP library available\")\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"SHAP library not available. Skipping SHAP analysis.\")\n",
    "    print(\"Install with: pip install shap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE:\n",
    "    # Sample data for SHAP (full dataset too slow)\n",
    "    sample_size = min(1000, len(X_val))\n",
    "    sample_idx = np.random.choice(X_val.index, size=sample_size, replace=False)\n",
    "    X_sample = X_val.loc[sample_idx]\n",
    "    \n",
    "    print(f\"Computing SHAP values for {sample_size} samples...\")\n",
    "    \n",
    "    # Create SHAP explainer based on model type\n",
    "    if 'LightGBM' in model_name or 'XGBoost' in model_name:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    \n",
    "    # For binary classification, shap_values might be a list\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # Use positive class\n",
    "    \n",
    "    print(f\"SHAP values computed. Shape: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE:\n",
    "    # Visualization 3: SHAP Summary Plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", max_display=15, show=False)\n",
    "    plt.title('SHAP Feature Importance (Top 15)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VISUALS_PATH / 'shap_importance_bar.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE:\n",
    "    # Visualization 4: SHAP Beeswarm Plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values, X_sample, max_display=15, show=False)\n",
    "    plt.title('SHAP Value Distribution (Top 15 Features)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VISUALS_PATH / 'shap_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE:\n",
    "    # Visualization 5: SHAP Waterfall for Individual Predictions\n",
    "    # Find a fraud case and a legitimate case\n",
    "    fraud_idx = X_sample[y_val.loc[sample_idx] == 1].index\n",
    "    legit_idx = X_sample[y_val.loc[sample_idx] == 0].index\n",
    "    \n",
    "    if len(fraud_idx) > 0:\n",
    "        # Get index position in X_sample\n",
    "        fraud_pos = np.where(X_sample.index == fraud_idx[0])[0][0]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        shap.plots.waterfall(shap.Explanation(\n",
    "            values=shap_values[fraud_pos],\n",
    "            base_values=explainer.expected_value if not isinstance(explainer.expected_value, list) else explainer.expected_value[1],\n",
    "            data=X_sample.iloc[fraud_pos],\n",
    "            feature_names=X_sample.columns.tolist()\n",
    "        ), max_display=15, show=False)\n",
    "        plt.title('SHAP Explanation for a Fraud Transaction', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(VISUALS_PATH / 'shap_waterfall_fraud.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b789f32",
   "metadata": {},
   "source": [
    "## 3. Error Analysis\n",
    "\n",
    "Understanding model errors is crucial for fraud detection:\n",
    "- **False Positives**: Legitimate transactions flagged as fraud (customer friction)\n",
    "- **False Negatives**: Fraud transactions missed (financial loss)\n",
    "\n",
    "We analyze patterns in errors to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2154842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create error analysis dataframe\n",
    "error_df = val_data.copy()\n",
    "error_df['predicted_proba'] = y_pred_proba\n",
    "error_df['predicted'] = y_pred\n",
    "error_df['actual'] = y_val.values\n",
    "\n",
    "# Categorize predictions\n",
    "def categorize_prediction(row):\n",
    "    if row['actual'] == 1 and row['predicted'] == 1:\n",
    "        return 'True Positive'\n",
    "    elif row['actual'] == 0 and row['predicted'] == 0:\n",
    "        return 'True Negative'\n",
    "    elif row['actual'] == 0 and row['predicted'] == 1:\n",
    "        return 'False Positive'\n",
    "    else:\n",
    "        return 'False Negative'\n",
    "\n",
    "error_df['prediction_type'] = error_df.apply(categorize_prediction, axis=1)\n",
    "\n",
    "# Summary\n",
    "print(\"Prediction Type Distribution:\")\n",
    "print(error_df['prediction_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 6: Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Legitimate', 'Fraud'],\n",
    "            yticklabels=['Legitimate', 'Fraud'])\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(VISUALS_PATH / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze False Positives (legitimate transactions flagged as fraud)\n",
    "false_positives = error_df[error_df['prediction_type'] == 'False Positive']\n",
    "true_negatives = error_df[error_df['prediction_type'] == 'True Negative']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FALSE POSITIVE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal False Positives: {len(false_positives)}\")\n",
    "print(f\"False Positive Rate: {len(false_positives) / len(true_negatives) * 100:.4f}%\")\n",
    "\n",
    "# Compare characteristics\n",
    "if 'TransactionAmt' in false_positives.columns:\n",
    "    print(f\"\\nTransaction Amount Comparison:\")\n",
    "    print(f\"  False Positives - Mean: ${false_positives['TransactionAmt'].mean():.2f}, \"\n",
    "          f\"Median: ${false_positives['TransactionAmt'].median():.2f}\")\n",
    "    print(f\"  True Negatives - Mean: ${true_negatives['TransactionAmt'].mean():.2f}, \"\n",
    "          f\"Median: ${true_negatives['TransactionAmt'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze False Negatives (fraud transactions missed)\n",
    "false_negatives = error_df[error_df['prediction_type'] == 'False Negative']\n",
    "true_positives = error_df[error_df['prediction_type'] == 'True Positive']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FALSE NEGATIVE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal False Negatives: {len(false_negatives)}\")\n",
    "print(f\"False Negative Rate: {len(false_negatives) / (len(false_negatives) + len(true_positives)) * 100:.2f}%\")\n",
    "\n",
    "if 'TransactionAmt' in false_negatives.columns:\n",
    "    print(f\"\\nTransaction Amount Comparison:\")\n",
    "    print(f\"  False Negatives - Mean: ${false_negatives['TransactionAmt'].mean():.2f}, \"\n",
    "          f\"Median: ${false_negatives['TransactionAmt'].median():.2f}\")\n",
    "    print(f\"  True Positives - Mean: ${true_positives['TransactionAmt'].mean():.2f}, \"\n",
    "          f\"Median: ${true_positives['TransactionAmt'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 7: Prediction Probability Distribution by Actual Class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution of probabilities\n",
    "for label, color, name in [(0, '#2ecc71', 'Legitimate'), (1, '#e74c3c', 'Fraud')]:\n",
    "    subset = error_df[error_df['actual'] == label]['predicted_proba']\n",
    "    axes[0].hist(subset, bins=50, alpha=0.6, color=color, label=name, density=True)\n",
    "\n",
    "axes[0].axvline(x=optimal_threshold, color='black', linestyle='--', \n",
    "                label=f'Threshold = {optimal_threshold:.3f}')\n",
    "axes[0].set_xlabel('Predicted Probability', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title('Prediction Probability Distribution by Actual Class', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot by prediction type\n",
    "error_df.boxplot(column='predicted_proba', by='prediction_type', ax=axes[1])\n",
    "axes[1].set_xlabel('Prediction Type', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Probability', fontsize=12)\n",
    "axes[1].set_title('Prediction Probability by Prediction Type', fontsize=14, fontweight='bold')\n",
    "axes[1].axhline(y=optimal_threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(VISUALS_PATH / 'prediction_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd53858",
   "metadata": {},
   "source": [
    "## 4. Error Analysis by Transaction Amount\n",
    "\n",
    "Understanding how model performance varies with transaction amount is critical\n",
    "because the business impact of fraud scales with amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create amount bins\n",
    "if 'TransactionAmt' in error_df.columns:\n",
    "    amount_bins = [0, 50, 100, 200, 500, 1000, 5000, float('inf')]\n",
    "    amount_labels = ['$0-50', '$50-100', '$100-200', '$200-500', '$500-1K', '$1K-5K', '$5K+']\n",
    "    \n",
    "    error_df['amount_bin'] = pd.cut(error_df['TransactionAmt'], bins=amount_bins, labels=amount_labels)\n",
    "    \n",
    "    # Calculate metrics by amount bin\n",
    "    amount_analysis = error_df.groupby('amount_bin', observed=True).apply(\n",
    "        lambda x: pd.Series({\n",
    "            'total': len(x),\n",
    "            'frauds': (x['actual'] == 1).sum(),\n",
    "            'fraud_rate': (x['actual'] == 1).mean() * 100,\n",
    "            'true_positives': ((x['actual'] == 1) & (x['predicted'] == 1)).sum(),\n",
    "            'false_negatives': ((x['actual'] == 1) & (x['predicted'] == 0)).sum(),\n",
    "            'false_positives': ((x['actual'] == 0) & (x['predicted'] == 1)).sum(),\n",
    "            'recall': ((x['actual'] == 1) & (x['predicted'] == 1)).sum() / max((x['actual'] == 1).sum(), 1) * 100,\n",
    "            'avg_fraud_amount': x[x['actual'] == 1]['TransactionAmt'].mean() if (x['actual'] == 1).sum() > 0 else 0\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(\"\\nPerformance Analysis by Transaction Amount:\")\n",
    "    print(amount_analysis.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 8: Performance by Transaction Amount\n",
    "if 'TransactionAmt' in error_df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Fraud rate by amount\n",
    "    axes[0, 0].bar(range(len(amount_analysis)), amount_analysis['fraud_rate'], \n",
    "                   color='steelblue', edgecolor='black')\n",
    "    axes[0, 0].set_xticks(range(len(amount_analysis)))\n",
    "    axes[0, 0].set_xticklabels(amount_analysis['amount_bin'], rotation=45)\n",
    "    axes[0, 0].set_ylabel('Fraud Rate (%)', fontsize=12)\n",
    "    axes[0, 0].set_title('Fraud Rate by Transaction Amount', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Recall by amount\n",
    "    axes[0, 1].bar(range(len(amount_analysis)), amount_analysis['recall'], \n",
    "                   color='coral', edgecolor='black')\n",
    "    axes[0, 1].set_xticks(range(len(amount_analysis)))\n",
    "    axes[0, 1].set_xticklabels(amount_analysis['amount_bin'], rotation=45)\n",
    "    axes[0, 1].set_ylabel('Recall (%)', fontsize=12)\n",
    "    axes[0, 1].set_title('Fraud Detection Recall by Amount', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].axhline(y=error_df[error_df['actual']==1]['predicted'].mean()*100, \n",
    "                       color='red', linestyle='--', label='Overall Recall')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # False Negatives by amount\n",
    "    axes[1, 0].bar(range(len(amount_analysis)), amount_analysis['false_negatives'], \n",
    "                   color='#e74c3c', edgecolor='black')\n",
    "    axes[1, 0].set_xticks(range(len(amount_analysis)))\n",
    "    axes[1, 0].set_xticklabels(amount_analysis['amount_bin'], rotation=45)\n",
    "    axes[1, 0].set_ylabel('Count', fontsize=12)\n",
    "    axes[1, 0].set_title('Missed Fraud Transactions by Amount', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # False Positives by amount\n",
    "    axes[1, 1].bar(range(len(amount_analysis)), amount_analysis['false_positives'], \n",
    "                   color='#f39c12', edgecolor='black')\n",
    "    axes[1, 1].set_xticks(range(len(amount_analysis)))\n",
    "    axes[1, 1].set_xticklabels(amount_analysis['amount_bin'], rotation=45)\n",
    "    axes[1, 1].set_ylabel('Count', fontsize=12)\n",
    "    axes[1, 1].set_title('False Alarms by Transaction Amount', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VISUALS_PATH / 'error_analysis_by_amount.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04c089",
   "metadata": {},
   "source": [
    "## 5. Threshold Analysis\n",
    "\n",
    "The classification threshold dramatically affects the precision-recall trade-off.\n",
    "Different business contexts may require different thresholds:\n",
    "- **High-value transactions**: Lower threshold (catch more fraud, accept more false positives)\n",
    "- **Customer experience focus**: Higher threshold (fewer false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f609f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance at different thresholds\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "\n",
    "# Calculate F1 for each threshold\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "# Create threshold analysis dataframe\n",
    "threshold_analysis = pd.DataFrame({\n",
    "    'threshold': list(thresholds) + [1.0],\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1_scores\n",
    "})\n",
    "\n",
    "# Sample some key thresholds\n",
    "key_thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "key_analysis = threshold_analysis[threshold_analysis['threshold'].apply(\n",
    "    lambda x: any(abs(x - t) < 0.05 for t in key_thresholds)\n",
    ")].drop_duplicates(subset=['threshold']).head(9)\n",
    "\n",
    "print(\"Performance at Different Thresholds:\")\n",
    "print(key_analysis.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53224f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 9: Threshold Trade-off Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Precision vs Recall at different thresholds\n",
    "axes[0].plot(thresholds, precision[:-1], label='Precision', linewidth=2)\n",
    "axes[0].plot(thresholds, recall[:-1], label='Recall', linewidth=2)\n",
    "axes[0].plot(thresholds, f1_scores[:-1], label='F1 Score', linewidth=2)\n",
    "axes[0].axvline(x=optimal_threshold, color='red', linestyle='--', \n",
    "                label=f'Optimal Threshold = {optimal_threshold:.3f}')\n",
    "axes[0].set_xlabel('Threshold', fontsize=12)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('Precision, Recall, F1 vs Threshold', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='center right')\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall curve\n",
    "axes[1].plot(recall, precision, linewidth=2, color='green')\n",
    "axes[1].fill_between(recall, precision, alpha=0.3, color='green')\n",
    "axes[1].set_xlabel('Recall', fontsize=12)\n",
    "axes[1].set_ylabel('Precision', fontsize=12)\n",
    "axes[1].set_title('Precision-Recall Trade-off', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Mark operating point\n",
    "idx = np.argmin(np.abs(thresholds - optimal_threshold))\n",
    "axes[1].scatter([recall[idx]], [precision[idx]], color='red', s=100, zorder=5,\n",
    "                label=f'Operating Point (t={optimal_threshold:.3f})')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(VISUALS_PATH / 'threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe90ff5e",
   "metadata": {},
   "source": [
    "## 6. Summary and Recommendations\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Most Important Features**: The model relies heavily on V-features (Vesta engineered features),\n",
    "   transaction amount, and card-related features.\n",
    "\n",
    "2. **Error Patterns**:\n",
    "   - False positives tend to be transactions with unusual but legitimate patterns\n",
    "   - False negatives often involve fraud that mimics normal behavior\n",
    "\n",
    "3. **Amount-Based Performance**:\n",
    "   - Performance varies across transaction amount ranges\n",
    "   - Higher-value transactions may need stricter thresholds\n",
    "\n",
    "### Recommendations for Production\n",
    "\n",
    "1. **Tiered Thresholds**: Consider different thresholds based on transaction amount\n",
    "2. **Feature Monitoring**: Track distributions of top features for drift detection\n",
    "3. **Regular Retraining**: Fraud patterns evolve; schedule regular model updates\n",
    "4. **Human Review Queue**: Route high-uncertainty predictions to manual review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9366e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature importance\n",
    "importance_df.to_csv(OUTPUT_PATH / 'metrics' / 'feature_importance.csv', index=False)\n",
    "\n",
    "# Save error analysis\n",
    "error_summary = error_df['prediction_type'].value_counts().to_dict()\n",
    "error_summary['optimal_threshold'] = optimal_threshold\n",
    "error_summary['model_name'] = model_name\n",
    "\n",
    "import json\n",
    "with open(OUTPUT_PATH / 'metrics' / 'error_analysis.json', 'w') as f:\n",
    "    json.dump(error_summary, f, indent=2)\n",
    "\n",
    "print(f\"Feature importance saved to: {OUTPUT_PATH / 'metrics' / 'feature_importance.csv'}\")\n",
    "print(f\"Error analysis saved to: {OUTPUT_PATH / 'metrics' / 'error_analysis.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL INTERPRETATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"\\nKey visualizations saved to: {VISUALS_PATH}\")\n",
    "print(f\"Analysis metrics saved to: {OUTPUT_PATH / 'metrics'}\")\n",
    "print(\"\\nAll notebooks complete. Check src/ for production scripts.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
